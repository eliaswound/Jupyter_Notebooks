{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e11cee92-7bb5-44ea-aaea-058f632b7049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is version 3.10 for smFISH spot detection. I have tried using pycharm + other python platform but in the end I feel like using Jupyter notebook is more suitable \n",
    "# Especailly for person who enter the Planarian Field might not understand coding/structure and other things too much. \n",
    "# This requires a enviornment and setting parameters. \n",
    "# https://stackoverflow.com/questions/58645807/change-interpreter-in-jupyter-notebook Please refer to this for setting up python interpreter. \n",
    "# This requires setting up a enviornment for 3D detection on stardist and bigfish. \n",
    "# Recommend to setup a enviornment for Stardist and then install bigfish/fishquant. \n",
    "# Please read instructions from Stardist to do so, and set python interpreter using the stackoverflow instructions. \n",
    "# Depend on your Image and settings this whole code need a while to run. I am making it as light as possible so please be patient. \n",
    "# I am also using tqdm in all of my customized code to show you process and the expected time in real time. \n",
    "# Please contact qingxuguan2020@u.northwestern.edu for any details/updates/help. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9c17c9ed-180c-4ec6-ae94-7e4cc0d56b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I will put most of the varaibles need for running python \n",
    "# File path: This will include: A control channel for checking intensities and other parameters\n",
    "# If there is no control channel, please change controlImage = False\n",
    "# counterstainChannelPath for smFISH channel, the signal you want to segement in this case \n",
    "# nucleiChannelPath for the nuclei channel locations \n",
    "# assuming you are running 3D detection. If not please develop a separate code for this. \n",
    "controlImage = False\n",
    "counterstainControlPath =\"/Users/eliasguan/Desktop/EG_0920_Test_wnt1_incision_amputation/Experiment_dataset/Experiment/0h_Amputation/Image1/633/0h_Amputation_Image1_633.tif\"\n",
    "counterstainChannelPath = \"/Users/eliasguan/Desktop/EG_0920_Test_wnt1_incision_amputation/Experiment_dataset/Experiment/0h_Amputation/Image1/633/0h_Amputation_Image1_633.tif\"\n",
    "nucleiSegmentationPath = \"/Users/eliasguan/Desktop/EG_0920_Test_wnt1_incision_amputation/Experiment_dataset/Experiment/0h_Amputation/Image1/565/results/labels\"\n",
    "# Set Parameters for detection. Here minimal distance is the minimal distance between spots. \n",
    "# Note this will be consistent for both control and the smFISH channel. \n",
    "# Unless specified separately, all these three number tuples are z,y,x in order. \n",
    "minimal_distance = (2,2,2)\n",
    "# Set the Gaussian LoG filter Kernel size. Recommend to start with 1,1.5,1.5 and increase if you need more. \n",
    "# I don`t think you need this different from control and experimental image. \n",
    "kernel_size = (1,1.5,1.5)\n",
    "# Set the voxel size. This is determined by the pixel size of your microscope. Please contact microscopt manufactuer and convert resolution to voxel size. \n",
    "# unit is nm, please change to nm and note this should be the same for control and your experimental image. \n",
    "# I specifically allow this code to run different voxel size for control and experimental image, but for a good experiment you should not do it like that. \n",
    "control_voxel_size = (361,75,75)\n",
    "voxel_size = (361,75,75)\n",
    "# Set the spot size as your expected spot size \n",
    "spot_size = (600, 300, 300)\n",
    "decomposition_thresh = (0.7,1,5)\n",
    "# Recommend start with 4 in planarian. You can have more. Recommend turn spotsRadiusDetection = True and run the radius test\n",
    "# Usually the largest radius/the average radius is what you want. \n",
    "min_spots_for_clusters = 4\n",
    "# Enter the radius for spot for detecting clusters. \n",
    "# If need refer to the spotsRadiusDetection to set a good reference\n",
    "radius_for_spots = 250 \n",
    "# Here you need to define the spot plotting size You can make it as large as possible. \n",
    "plot_spot_size = 4\n",
    "# Here you add the nuclei projection size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "83421ae3-d57b-4af0-b7ea-853a59d1863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we get some advanced settings: \n",
    "# Spot_radius detections\n",
    "# automated False, turn to True if you need the code to detect a correct average spotRadius, in pixels for you. \n",
    "spotsRadiusDetection = True\n",
    "# Lets see if you want to save the Spot infomation. I turn it to True by default, but in general you dont need to do that. \n",
    "saveSpotInformation = True \n",
    "# Lets set this for Plotting Outer Circle. \n",
    "# If you want to plot Inner Circle Please set this to False \n",
    "plotInnerCircle = False \n",
    "# If you need to plot exact spot location, turn this to True. In this case the plot_spot_size will be rendered off since there is no need for plotting spot size. \n",
    "# Note this function is still under development. Please, be aware and I dont recommend turn it on. \n",
    "plotExactSpot = False\n",
    "# Adjust the outer layer size here if you need \n",
    "exactSpotSize = 2\n",
    "# Open this if you want to plot each spot by number. I do not recommend turn this on since this will largely increase the image size and does not help with anything. \n",
    "# If you need this note you need to have at most 65536 spots. If you have more manually change the dtype in the empty image but I dont think anyone need this much of image. \n",
    "plotSpotLabel = False \n",
    "labelExpansionSize = 20\n",
    "nuclei_projection_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2e6a7de5-cf39-4c70-b715-5e20ec29bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is for importing all the functions for smFISH detection. Please install them if you dont have these pacakges. \n",
    "import os\n",
    "import sys\n",
    "# import tk for getting the directory faster. dont need this in a command line/server version\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "import numpy as np\n",
    "import bigfish.detection \n",
    "import bigfish.stack\n",
    "import bigfish.plot\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "# if you dont need to plot in jupyter you don need these. Some magic interperters need to be removed for command line version. \n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"image.interpolation\"] = 'none'\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# Glob and tifffile are needed\n",
    "from glob import glob\n",
    "from tifffile import imread,imwrite\n",
    "# csb deep is to take normalization \n",
    "from csbdeep.utils import Path, normalize\n",
    "from csbdeep.io import save_tiff_imagej_compatible\n",
    "# This is your stardist models and everything in stardist coming from. \n",
    "from stardist import random_label_cmap, _draw_polygons, export_imagej_rois\n",
    "from stardist.models import StarDist2D\n",
    "from skimage import segmentation\n",
    "import bigfish.multistack as multistack\n",
    "# Set random seed for you color map. You do not really need this to be 6 all the time, but its okay. \n",
    "np.random.seed(6)\n",
    "lbl_cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a51238c8-81f0-48f2-8abb-838143ef18fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy_file(filename):\n",
    "    try:\n",
    "        data = np.load(filename)\n",
    "        print(f\"Loaded {filename} successfully.\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{filename} not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filename}: {e}\")\n",
    "    return None\n",
    "def make_stardist_Predictions_labels (dataset, normalized = False, normalize_low = 0, normalize_high = 0, nms_thresh = 0, prob_thresh = 0): \n",
    "    ''' input: csbdeep input: If this image is a csbdeep filtered image. If this is true, the image will not be normalized. \n",
    "               dataset: The data set you want to analysis on \n",
    "               normalize_low and normalized_high: The parameter you want to normalize, if either of them is 0 will use default value (1,99.8)\n",
    "               if not then will use these values \n",
    "               nms_thresh and prob_thrsh : the parameter of overlapping and probablity threshold. If eitehr of them is 0 will use default value \n",
    "               for the model (depend on the model) if not then use these values\n",
    "    '''\n",
    "    labels_collection= []\n",
    "    for i in range(len(dataset)): \n",
    "        if not normalized:\n",
    "            if normalize_low ==0 or normalize_high == 0:\n",
    "                img = normalize(dataset[i], 1,99.8, axis=(0,1))\n",
    "            else:\n",
    "                img = normalize(dataset[i], normalize_low, normalize_high, axis=(0,1))\n",
    "        else:\n",
    "            img = dataset[i]\n",
    "        if nms_thresh == 0 or prob_thresh == 0 :\n",
    "            labels, details = model.predict_instances(img)\n",
    "        else: \n",
    "            labels, details = model.predict_instances(img,nms_thresh = nms_thresh, prob_thresh = prob_thresh)\n",
    "        # write labels\n",
    "        labels_collection.append(labels)\n",
    "        export_imagej_rois('polygons/polygon_rois_'+str(i).zfill(3)+'.zip', details['coord'])\n",
    "        imwrite(\"labels/Nucleus_Labels_\"+str(i).zfill(3)+\".tif\", labels)\n",
    "    labels_collection = np.array(labels_collection, dtype = np.uint16)\n",
    "    return labels_collection\n",
    "def random_select_images(dataset, percentage):\n",
    "    \"\"\"\n",
    "    Randomly select a certain percentage of images from the dataset.\n",
    "\n",
    "    Parameters:\n",
    "        dataset (list): A list containing 2D arrays (images).\n",
    "        percentage (float): Percentage of images to be selected.\n",
    "\n",
    "    Returns:\n",
    "        selected_indices (list): A list of indices corresponding to the selected images.\n",
    "    \"\"\"\n",
    "    num_images = len(dataset)\n",
    "    num_selected = int(np.ceil(percentage/100 * num_images))\n",
    "    selected_indices = np.random.choice(num_images, num_selected, replace=False)\n",
    "    return selected_indices\n",
    "\n",
    "def random_select_region(image, region_size):\n",
    "    \"\"\"\n",
    "    Randomly select a region within the image with a certain size.\n",
    "\n",
    "    Parameters:\n",
    "        image (2D array): The original image.\n",
    "        region_size (tuple): The size of the region to be selected (height, width).\n",
    "\n",
    "    Returns:\n",
    "        region (2D array): The selected region.\n",
    "    \"\"\"\n",
    "    image_height, image_width = image.shape\n",
    "    region_height, region_width = region_size\n",
    "\n",
    "    if region_height > image_height or region_width > image_width:\n",
    "        raise ValueError(\"Region size exceeds original image size.\")\n",
    "\n",
    "    start_row = np.random.randint(0, image_height - region_height + 1)\n",
    "    start_col = np.random.randint(0, image_width - region_width + 1)\n",
    "    end_row = start_row + region_height\n",
    "    end_col = start_col + region_width\n",
    "\n",
    "    region_prop = [(start_row, end_row),(start_col,end_col)]\n",
    "    return region_prop\n",
    "def make_random_examples(dataset, normalize_low = 0, normalize_high =0, nms_thresh =0, prob_thresh = 0, normalized = False, percentage = 20, region_size = (500,500)):\n",
    "    selected_indicies = sorted(random_select_images(dataset, percentage))\n",
    "    for item in selected_indicies: \n",
    "        if normalized:\n",
    "            img = dataset[item]\n",
    "        else:\n",
    "            if normalize_low ==0 or normalize_high == 0:\n",
    "                img = normalize(dataset[item], 1,99.8, axis=(0,1))\n",
    "            else:\n",
    "                img = normalize(dataset[item], normalize_low, normalize_high, axis=(0,1))   \n",
    "        if nms_thresh == 0 or prob_thresh == 0 :\n",
    "            labels, details = model.predict_instances(img)\n",
    "        else: \n",
    "            labels, details = model.predict_instances(img, nms_thresh = nms_thresh, prob_thresh = prob_thresh)\n",
    "        region_props =  random_select_region(img, region_size)\n",
    "        cropped_image = img[region_props[0][0]:region_props[0][1],region_props[1][0]:region_props[1][1]]\n",
    "        cropped_label = labels[region_props[0][0]:region_props[0][1],region_props[1][0]:region_props[1][1]]\n",
    "        figure = plt.figure(figsize=(13,10))\n",
    "        coord, points, prob = details['coord'], details['points'], details['prob']\n",
    "        # Plot image on the first one\n",
    "        ax1 = figure.add_subplot(121); ax1.imshow(cropped_image, cmap='gray'); ax1.axis('off')\n",
    "        # Plot image on the second one\n",
    "        ax2 = figure.add_subplot(122); ax2.imshow(cropped_image, cmap='gray'); ax2.axis('off')\n",
    "        # Plot labels on the third one. \n",
    "        ax2.imshow(cropped_label, cmap=lbl_cmap, alpha=0.3)\n",
    "        figure.tight_layout()\n",
    "        plt.savefig(\"random_examples/random_example_\"+str(item).zfill(3)+\".tif\")\n",
    "def create_folder_in_same_directory(file_path, folder_name):\n",
    "    \"\"\"\n",
    "    Creates a folder with the specified name in the same directory as the given file.\n",
    "    If the folder already exists, it returns the existing path.\n",
    "    \"\"\"\n",
    "    # Get the directory of the given file\n",
    "    directory = os.path.dirname(file_path)\n",
    "    \n",
    "    # Define the path for the specified folder\n",
    "    folder_path = os.path.join(directory, folder_name)\n",
    "    \n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        # Create the folder if it doesn't exist\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Created '{folder_name}' folder at: {folder_path}\")\n",
    "    else:\n",
    "        print(f\"'{folder_name}' folder already exists at: {folder_path}\")\n",
    "    \n",
    "    return folder_path\n",
    "def generate_max_projection_array(array, projection_size):\n",
    "    ranges = []\n",
    "    total = array.shape[0]\n",
    "    projected_image = []\n",
    "    for i in range(0, total, projection_size):\n",
    "        start = i\n",
    "        end = min(i + projection_size - 1, total - 1)\n",
    "        ranges.append((start, end))\n",
    "    for item in ranges:\n",
    "        start, end = item\n",
    "\n",
    "        for i in range(start,end):\n",
    "            nuclei_array.append(array[i])\n",
    "        projection = bigfish.stack.maximum_projection(np.array(nuclei_array,dtype=np.uint8))\n",
    "        projected_image.append(projection)\n",
    "    return np.array(projected_image,dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d0903936-8d4e-4ad1-8723-b81968d88212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded spots_post_decomposition_and_background_removed.npy successfully.\n"
     ]
    }
   ],
   "source": [
    "# Get into your counterstain spots\n",
    "os.chdir(os.path.dirname(counterstainChannelPath))\n",
    "os.chdir(\"results\")\n",
    "# Read in your counterstain spots file \n",
    "# File names\n",
    "file_A = 'spots_post_decomposition_and_background_removed.npy'\n",
    "file_B = 'spots_post_decomposition.npy'\n",
    "\n",
    "# Try loading A, fallback to B if A fails\n",
    "post_decomposition_array = load_npy_file(file_A)\n",
    "if post_decomposition_array is None:\n",
    "    post_decomposition_array = load_npy_file(file_B)\n",
    "post_decomposition_array_projected = np.copy(post_decomposition_array)  # Create a copy of the original array\n",
    "post_decomposition_array_projected[:, 0] = np.floor_divide(post_decomposition_array[:, 0], nuclei_projection_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "43ea5894-840e-4524-975e-060ea09d6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(nucleiSegmentationPath)\n",
    "nucleiFileNames = sorted(glob(\"*.tif\"))\n",
    "nucleiImageArray_projected_labels = []\n",
    "for item in nucleiFileNames:\n",
    "    nucleiImage = imread(item)\n",
    "    nucleiImageArray_projected_labels.append(nucleiImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "73613527-9466-4ac8-bb03-baca9f2be46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'expanded_labels' folder already exists at: expanded_labels\n",
      "Created 'counterstain_labels' folder at: counterstain_labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 7367/7367 [13:52<00:00,  8.85it/s]\n",
      "100%|███████████████████████████████████████| 7851/7851 [14:42<00:00,  8.90it/s]\n",
      "100%|███████████████████████████████████████| 7897/7897 [14:50<00:00,  8.87it/s]\n",
      "100%|███████████████████████████████████████| 6396/6396 [12:00<00:00,  8.88it/s]\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(counterstainChannelPath))\n",
    "os.chdir(\"results\")\n",
    "create_folder_in_same_directory(\".\", \"expanded_labels\")\n",
    "create_folder_in_same_directory(\".\", \"counterstain_labels\")\n",
    "spot_in_background = []\n",
    "counterstain_assignment_results = []\n",
    "for i in range(len(nucleiImageArray_projected_labels)):\n",
    "    # Expanding labels \n",
    "    expanded_labels = segmentation.expand_labels(nucleiImageArray_projected_labels[i], distance=labelExpansionSize)\n",
    "    # Find your spots belong to this projection \n",
    "    indices = np.where(post_decomposition_array_projected[:, 0] == i)[0]\n",
    "    # Remove the z-stack information from your RNA detection\n",
    "    rna_coord = post_decomposition_array_projected[indices][:, -2:]\n",
    "    # Data type configureation. Changing dtype will probablly \n",
    "    # Get you more compatible with bigfish also makes calculation easier\n",
    "    expanded_labels = expanded_labels.astype(dtype=np.uint16)\n",
    "    rna_coord = rna_coord.astype(dtype=\"int64\")\n",
    "    # Save your expanded labels \n",
    "    imwrite('expanded_labels/20expandedlabel'+str(i).zfill(3)+'.tif', expanded_labels, photometric = 'minisblack')\n",
    "    # Get cell RNA counter as a zero array \n",
    "    cell_RNACount = np.zeros(np.max(expanded_labels)+1)\n",
    "    # Iterate through your RNA coordinates \n",
    "    for item in rna_coord:\n",
    "        # Find the value of this RNA center spot\n",
    "        location = expanded_labels[item[0],item[1]]\n",
    "        # Add on to your RNA counter\n",
    "        cell_RNACount[location] = cell_RNACount[location]+1\n",
    "    # Add your results to your collection\n",
    "    counterstain_assignment_results.append(cell_RNACount)\n",
    "    # Create empty assignment maps \n",
    "    assignment_map = np.zeros(expanded_labels.shape, dtype = np.uint8)\n",
    "    # Create your maps \n",
    "    for j in tqdm(range(1,len(cell_RNACount))):\n",
    "        indices = np.where(expanded_labels == j)\n",
    "        assignment_map[indices] = cell_RNACount[j]\n",
    "    spot_in_background.append(cell_RNACount[0])\n",
    "    imwrite('counterstain_labels/assignment_map'+str(i).zfill(3)+'.tif', assignment_map, photometric = 'minisblack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a8340999-0c81-4665-80db-db1a3f61ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"counterstain_assignment_result.npz\", *counterstain_assignment_results)\n",
    "np.save(\"counterstain_spot_in_background.npy\", spot_in_background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edaf5e8-c8e8-40de-8a4f-52363b536d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stardist-env",
   "language": "python",
   "name": "stardist-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
